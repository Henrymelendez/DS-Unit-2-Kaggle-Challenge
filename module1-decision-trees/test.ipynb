{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler,LabelEncoder\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('test_features.csv')\n",
    "train_features = pd.read_csv('train_features.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['date_recorded'] = pd.to_datetime(train_features['date_recorded'], infer_datetime_format=True)\n",
    "test_features['date_recorded'] = pd.to_datetime(test_features['date_recorded'], infer_datetime_format=True)\n",
    "train_features['water_per_pop'] = train_features['amount_tsh']/train_features['population']\n",
    "test_features['water_per_pop'] = test_features['amount_tsh']/test_features['population']  \n",
    "train_features['water_per_pop'] = train_features['water_per_pop'].replace([np.inf, -np.inf], np.nan)\n",
    "test_features['water_per_pop'] = test_features['water_per_pop'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(X):\n",
    "    X['construction_year'] = X['construction_year'].replace(np.nan, 2000)\n",
    "    X['construction'] = X['construction_year'] != 0\n",
    "    X['water_per_pop'] = X['water_per_pop'].replace(np.nan, 0)\n",
    "    return X\n",
    "train_features = feature_engineering(train_features)\n",
    "test_features = feature_engineering(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering2(X):   \n",
    "    X['year'] = X['date_recorded'].dt.year\n",
    "    X['month'] = X['date_recorded'].dt.month\n",
    "    X['week'] = X['date_recorded'].dt.week\n",
    "    X['age'] = X['year'] -X['construction_year']\n",
    "    X['age'].loc[X['age'] == X['year']] = 0\n",
    "    X['date_recorded'] = X['date_recorded'].astype(str)\n",
    "    return X\n",
    "\n",
    "train_features = feature_engineering2(train_features)\n",
    "test_features = feature_engineering2(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(X):\n",
    "    X['public_meeting'] = X['public_meeting'].fillna(lambda x: random.choice(X[X['public_meeting'] != np.nan])['public_meeting'])\n",
    "    X['permit'] = X['permit'].fillna(lambda x: random.choice(X[X['permit'] != np.nan])['permit'])\n",
    "    X['age'] = X['age'].replace(0, round(X['age'].mean()))\n",
    "    X['gps_height'] = X['gps_height'].replace(0, round(X['gps_height'].median()))\n",
    "    X['source_type'] = X['source_type'].fillna(lambda x: random.choice(X[X['source_type'] != 'other'])['source_type'])\n",
    "    X['scheme_management'] = X['scheme_management'].replace(np.nan,0)\n",
    "    X['scheme_management'] = X['scheme_management'].replace(0,'Unknown')\n",
    "    X['funder'] = X['funder'].fillna(lambda x: random.choice(X[X['funder'] != np.nan])['funder'])\n",
    "    X['installer'].replace(np.nan,0, inplace= True)\n",
    "    X['installer'] = X['installer'].replace('-', \"Other\")\n",
    "    X['installer'] = X['installer'].replace(0, \"Other\")\n",
    "    X['date_recorded'] = X['date_recorded'].astype(str)\n",
    "    X['construction']= X['construction'].astype('str')\n",
    "    X['population']= X['population'].astype('float64')      \n",
    "    X['gps_height']= X['gps_height'].astype('float64')\n",
    "    return X\n",
    "train_features = fill_nan(train_features)\n",
    "test_features =fill_nan(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_col(X):\n",
    "    organize= {'india mark ii': 'india',\n",
    "    'india mark iii': 'india',\n",
    "    'other - swn 81': 'swn',\n",
    "    'swn 80': 'swn',\n",
    "    'other - play pump': 'other handpump',\n",
    "    'walimi': 'other handpump',\n",
    "    'other - mkulima/shinyanga' : 'other handpump',\n",
    "    'cemo': 'other motorpump',\n",
    "    'climax': 'other motorpump'}\n",
    "    X['extraction_type']= X['extraction_type'].replace(organize)\n",
    "\n",
    "    \n",
    "    return X\n",
    "train_features = clean_col(train_features)\n",
    "test_features = clean_col(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_col(X):\n",
    "    drop_cols = ['wpt_name',    # too many levels \n",
    "    'subvillage',  # too many levels; we have lat and long for location\n",
    "    'ward',        # too many levels; we have lat and long for location\n",
    "    'recorded_by', # constant\n",
    "    'scheme_name', # too many levels\n",
    "    'num_private', # irrelevant\n",
    "    'region_code', # too many levels; we have lat and long for location\n",
    "    'quantity_group', #same as quantity column\n",
    "    'source_type',   #same as source but with fewer levels\n",
    "    'waterpoint_type_group', #same as waterpoint\n",
    "    'payment_type']          #same as payment\n",
    "    X = X.drop(columns= drop_cols)\n",
    "    return X\n",
    "train_features = drop_col(train_features)\n",
    "test_features = drop_col(test_features)\n",
    "train_labels = train_labels.drop(columns='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_features['installer'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "id                         int64\namount_tsh               float64\ndate_recorded             object\nfunder                    object\ngps_height               float64\ninstaller                 object\nlongitude                float64\nlatitude                 float64\nbasin                     object\nregion                    object\ndistrict_code              int64\nlga                       object\npopulation               float64\npublic_meeting            object\nscheme_management         object\npermit                    object\nconstruction_year          int64\nextraction_type           object\nextraction_type_group     object\nextraction_type_class     object\nmanagement                object\nmanagement_group          object\npayment                   object\nwater_quality             object\nquality_group             object\nquantity                  object\nsource                    object\nsource_class              object\nwaterpoint_type           object\nwater_per_pop            float64\nconstruction              object\nyear                       int64\nmonth                      int64\nweek                       int64\nage                        int64\ndtype: object"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['date_recorded',\n 'funder',\n 'installer',\n 'basin',\n 'region',\n 'lga',\n 'public_meeting',\n 'scheme_management',\n 'permit',\n 'extraction_type',\n 'extraction_type_group',\n 'extraction_type_class',\n 'management',\n 'management_group',\n 'payment',\n 'water_quality',\n 'quality_group',\n 'quantity',\n 'source',\n 'source_class',\n 'waterpoint_type',\n 'construction']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "cat_cols=train_features.select_dtypes(include=['object']).columns.values.tolist()\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, random_state=42, test_size=.2)\n",
    "X_test= test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "encoder = ce.OrdinalEncoder()\n",
    "\n",
    "# Fit & Transform\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "# Scale - Only the continuous. I found scaling all features made prediction worse\n",
    "\n",
    "continuous_col = ['population','gps_height','week','month','year','age','longitude','latitude'] \n",
    "\n",
    "scaled = MinMaxScaler()\n",
    "X_train[continuous_col] = scaled.fit_transform(X_train[continuous_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Fit X_val\n",
    "X_val = encoder.transform(X_val)\n",
    "\n",
    "# Partial scale x_val\n",
    "X_val[continuous_col] = scaled.fit_transform(X_val[continuous_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  8.5min remaining: 12.8min\n[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  8.5min finished\nTraining Accuracy Score: 0.8039772727272727\n"
    }
   ],
   "source": [
    "# Define parameters for the model\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Define the model and input inside RSCV\n",
    "model = \n",
    "# RSCV\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    scoring='accuracy',\n",
    "    n_iter=9,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=5,\n",
    "    return_train_score=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to training data\n",
    "search.fit(X_train, y_train)\n",
    "print('Training Accuracy Score:', search.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Validation Set Accuracy Score: 0.8004208754208754\n"
    }
   ],
   "source": [
    "best = search.best_estimator_\n",
    "y_pred = best.predict(X_val)\n",
    "print('Validation Set Accuracy Score:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = search.best_estimator_\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "# Partial scale x_test\n",
    "X_test[continuous_col] = scaled.fit_transform(X_test[continuous_col])\n",
    "y_pred_test = best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = y_pred_test\n",
    "submission.to_csv('henry.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bit56b463bb8c13454f884b8f319dfe3a26",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}